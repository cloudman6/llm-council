"""3-stage LLM Council orchestration."""

from typing import List, Dict, Any, Optional
import json
from .openrouter import query_models_parallel, query_model
from .config import COUNCIL_MODELS, CHAIRMAN_MODEL


async def divergent_phase_responses(user_query: str) -> List[Dict[str, Any]]:
    """
    Divergent Phase: responses where each model provides their own perspective without seeing others' responses.

    Args:
        user_query: The user's question

    Returns:
        List of dicts with 'model', 'response', and 'parsed_json' keys
    """
    divergent_results = []

    # Build prompt for responses (no accumulated context)
    prompt = build_divergent_prompt(user_query)

    # Query all models in parallel for responses
    responses = await query_models_parallel(COUNCIL_MODELS, [{"role": "user", "content": prompt}])

    # Process responses
    for model, response in responses.items():
        if response is not None:
            response_text = response.get('content', '')

            # Log response for debugging
            print(f"\n=== Response from {model} ===", flush=True)
            print(f"Response length: {len(response_text)} characters", flush=True)
            print("Response content:", flush=True)
            print("-" * 80, flush=True)
            print(response_text, flush=True)
            print("-" * 80, flush=True)

            # Validate and parse JSON
            parsed_json = validate_and_parse_json(response_text, model)

            result = {
                "model": model,
                "response": response_text,
                "parsed_json": parsed_json
            }

            divergent_results.append(result)
        else:
            # If model fails, continue with next model
            print(f"Warning: Model {model} failed to respond in divergent phase")

    return divergent_results



async def generate_conversation_title(user_query: str) -> str:
    """
    Generate a short title for a conversation based on the first user message.

    Args:
        user_query: The first user message

    Returns:
        A short title (3-5 words)
    """
    title_prompt = f"""Generate a very short title (3-5 words maximum) that summarizes the following question.
The title should be concise and descriptive. Do not use quotes or punctuation in the title.

Question: {user_query}

Title:"""

    messages = [{"role": "user", "content": title_prompt}]

    # Use gemini-2.5-flash for title generation (fast and cheap)
    response = await query_model("google/gemini-2.5-flash", messages, timeout=30.0)

    if response is None:
        # Fallback to a generic title
        return "New Conversation"

    title = response.get('content', 'New Conversation').strip()

    # Clean up the title - remove quotes, limit length
    title = title.strip('"\'')

    # Truncate if too long
    if len(title) > 50:
        title = title[:47] + "..."

    return title


def build_divergent_prompt(user_query: str) -> str:
    """
    Build prompt for divergent phase where each model responds without seeing others' responses.

    Args:
        user_query: The user's question

    Returns:
        Formatted prompt string
    """
    # Optimized divergent phase prompt for responses
    system_prompt = """# è§’è‰²ä¸ä»»åŠ¡

## è§’è‰²å®šä¹‰
ä½ æ˜¯å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿçš„ AI æ¨¡å‹ï¼Œå‚ä¸å‘æ•£é˜¶æ®µçš„è®¨è®ºã€‚ä½ å°†ç‹¬ç«‹æä¾›è§‚ç‚¹ï¼Œçœ‹ä¸åˆ°å…¶ä»–æ¨¡å‹çš„æƒ³æ³•ã€‚

## æ ¸å¿ƒä»»åŠ¡
- å›´ç»•ç”¨æˆ·é—®é¢˜æä¾›ä½ ç‹¬ç‰¹çš„è§‚ç‚¹
- ä»ä½ çš„è§’åº¦åˆ†æé—®é¢˜ï¼Œç‹¬ç«‹æ€è€ƒ
- ä½¿ç”¨ç»“æ„åŒ– JSON æ ¼å¼è¾“å‡º

---

# è¾“å‡ºæ ¼å¼

å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼ï¼š

```json
{{
  "summary": "ä½ å¯¹é—®é¢˜çš„æ€è€ƒç®€è¿°",
  "viewpoints": ["ä½ çš„ä¸»è¦è§‚ç‚¹1", "ä½ çš„ä¸»è¦è§‚ç‚¹2", "ä½ çš„ä¸»è¦è§‚ç‚¹3", ...],
  "final_answer_candidate": "åŸºäºä½ çš„ç‹¬ç«‹åˆ†æç»™å‡ºçš„åˆæ­¥ç­”æ¡ˆ"
}}
```

---

# ç”¨æˆ·åŸå§‹é—®é¢˜
{user_query}

---

# å¼€å§‹å›ç­”
è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®š JSON æ ¼å¼è¾“å‡ºä½ çš„ç‹¬ç«‹è§‚ç‚¹ã€‚"""

    return system_prompt.format(user_query=user_query)


def validate_and_parse_json(response_text: str, model_name: str) -> Dict[str, Any]:
    """
    Validate and parse JSON response with retry logic.

    Args:
        response_text: The raw response text from the model
        model_name: Name of the model for error reporting

    Returns:
        Parsed JSON dict or empty dict if validation fails
    """
    # Try to parse JSON
    try:
        # Remove any markdown code block markers
        cleaned_text = response_text.strip()
        if cleaned_text.startswith('```json'):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.startswith('```'):
            cleaned_text = cleaned_text[3:]
        if cleaned_text.endswith('```'):
            cleaned_text = cleaned_text[:-3]

        parsed = json.loads(cleaned_text.strip())

        # Validate required fields for convergent phase
        required_fields = ['summary', 'viewpoints', 'final_answer_candidate']

        # Optional fields for convergent phase analysis
        optional_fields = ['consensus_analysis', 'conflict_analysis', 'conflicts', 'suggestions']

        for field in required_fields:
            if field not in parsed:
                print(f"Warning: Model {model_name} missing required field '{field}' in JSON")
                # Try to create missing field from available data
                if field == 'viewpoints' and 'summary' in parsed:
                    parsed['viewpoints'] = [parsed['summary']]
                elif field == 'summary' and 'viewpoints' in parsed:
                    parsed['summary'] = ' '.join(parsed['viewpoints'][:2]) if parsed['viewpoints'] else "No summary provided"
                else:
                    parsed[field] = "" if field == 'final_answer_candidate' else []

        # Ensure optional fields exist with appropriate defaults
        for field in optional_fields:
            if field not in parsed:
                if field in ['consensus_analysis', 'conflict_analysis']:
                    parsed[field] = []  # These should be arrays of objects
                else:
                    parsed[field] = []  # conflicts and suggestions should be arrays

        return parsed

    except json.JSONDecodeError as e:
        print(f"Warning: Model {model_name} returned invalid JSON: {e}")
        print(f"Response text: {response_text}")
        return {}


async def evaluate_convergence(
    user_query: str,
    round_responses: List[Dict[str, Any]],
    round_number: int,
    previous_chairman_response: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Evaluate convergence and generate chairman's assessment.

    Args:
        user_query: The user's question
        round_responses: List of model responses for this round
        round_number: Current round number (1 for divergent, 2+ for convergent)
        previous_chairman_response: Previous round's chairman assessment for context

    Returns:
        Chairman's assessment in JSON format
    """
    # Build responses text for chairman
    responses_text = "\n\n".join([
        f"{result['model']}:\n{result['response']}"
        for result in round_responses
    ])

    # Build previous chairman context section if available
    previous_chairman_context = ""
    if previous_chairman_response and round_number > 1:
        # Format the detailed previous round context for better comparison
        prev_consensus = previous_chairman_response.get('consensus_points', [])
        prev_conflicts = previous_chairman_response.get('conflict_points', [])
        prev_questions = previous_chairman_response.get('questions_for_next_round', [])
        prev_score = previous_chairman_response.get('convergence_score', 'N/A')
        prev_converged = previous_chairman_response.get('is_converged', 'N/A')
        prev_explanation = previous_chairman_response.get('explanation', 'N/A')

        previous_chairman_context = f"""

## ä¸Šä¸€è½®è®¨è®ºçŠ¶æ€å›é¡¾ (ç¬¬{round_number-1}è½®)

### ä¸Šä¸€è½®å…³é”®æŒ‡æ ‡
- **æ”¶æ•›è¯„åˆ†**: {prev_score}/1.0
- **æ”¶æ•›çŠ¶æ€**: {prev_converged}

### ä¸Šä¸€è½®è¯†åˆ«çš„å…±è¯†ç‚¹
{chr(10).join([f"- {point}" for point in prev_consensus]) if prev_consensus else "- æ— æ˜ç¡®å…±è¯†ç‚¹"}

### ä¸Šä¸€è½®è¯†åˆ«çš„ä¸»è¦å†²çªç‚¹
{chr(10).join([f"- {point}" for point in prev_conflicts]) if prev_conflicts else "- æ— æ˜¾è‘—å†²çªç‚¹"}

### ä¸Šä¸€è½®æå‡ºçš„å¼•å¯¼é—®é¢˜
{chr(10).join([f"{i+1}. {q}" for i, q in enumerate(prev_questions)]) if prev_questions else "- æ— ç‰¹å®šå¼•å¯¼é—®é¢˜"}

### ä¸Šä¸€è½®æ”¶æ•›åˆ†æ
{prev_explanation}

## ğŸ” æœ¬è½®å¯¹æ¯”åˆ†æè¦æ±‚

**åœ¨è¯„ä¼°æœ¬è½®è®¨è®ºæ—¶ï¼Œä½ å¿…é¡»è¿›è¡Œä»¥ä¸‹å¯¹æ¯”åˆ†æï¼š**

### 1. è§‚ç‚¹æ¼”è¿›å¯¹æ¯”
- **å¯¹æ¯”ä¸Šä¸€è½®å…±è¯†ç‚¹**: æœ¬è½®æ˜¯å¦å¼ºåŒ–äº†è¿™äº›å…±è¯†ï¼Ÿæ˜¯å¦æœ‰æ‰€ä¿®æ­£ï¼Ÿ
- **å¯¹æ¯”ä¸Šä¸€è½®å†²çªç‚¹**: æœ¬è½®æ˜¯å¦è§£å†³äº†è¿™äº›å†²çªï¼Ÿæ˜¯å¦äº§ç”Ÿäº†æ–°çš„å†²çªï¼Ÿ
- **æ–°è§‚ç‚¹è¯†åˆ«**: æœ¬è½®å‡ºç°äº†å“ªäº›ä¸Šä¸€è½®æ²¡æœ‰çš„æ–°è§‚ç‚¹æˆ–æ–°è§’åº¦ï¼Ÿ

### 2. è®¨è®ºè¿›å±•è¯„ä¼°
- **é—®é¢˜å“åº”åº¦**: æœ¬è½®å›å¤æ˜¯å¦æœ‰æ•ˆå›åº”äº†ä¸Šä¸€è½®æå‡ºçš„å¼•å¯¼é—®é¢˜ï¼Ÿ
- **æ”¶æ•›è½¨è¿¹**: è®¨è®ºæ˜¯æœç€æ”¶æ•›æ–¹å‘å‘å±•è¿˜æ˜¯å‡ºç°äº†æ–°çš„åˆ†æ­§ï¼Ÿ
- **æ·±åº¦å˜åŒ–**: ç›¸æ¯”ä¸Šä¸€è½®ï¼Œè®¨è®ºçš„æ·±åº¦å’Œå¹¿åº¦æ˜¯å¦æœ‰æå‡ï¼Ÿ

### 3. å†³ç­–ä¾æ®
- **ç¨³å®šæ€§åˆ¤æ–­**: æœ¬è½®ç›¸æ¯”ä¸Šä¸€è½®æ˜¯å¦æ›´åŠ ç¨³å®šï¼ˆè§‚ç‚¹ä¸å†å¤§å¹…å˜åŒ–ï¼‰ï¼Ÿ
- **å……åˆ†æ€§è¯„ä¼°**: ç°æœ‰çš„å…±è¯†ç‚¹å’Œå·²è§£å†³çš„å†²çªç‚¹æ˜¯å¦è¶³ä»¥å½¢æˆé«˜è´¨é‡ç­”æ¡ˆï¼Ÿ
- **å‰©ä½™åˆ†æ­§ä»·å€¼**: å‰©ä½™çš„åˆ†æ­§ç‚¹æ˜¯å¦å¯¹æœ€ç»ˆç­”æ¡ˆè´¨é‡æœ‰å®è´¨æ€§å½±å“ï¼Ÿ

**ç‰¹åˆ«æ³¨æ„**: æ”¶æ•›ä¸ç­‰äºå®Œå…¨ä¸€è‡´ï¼Œè€Œæ˜¯æŒ‡è®¨è®ºæ¡†æ¶ç¨³å®šã€åˆ†æ­§æ˜ç¡®ä¸”å¯æ§ï¼Œèƒ½å¤Ÿå½¢æˆç»¼åˆæ€§çš„é«˜è´¨é‡ç­”æ¡ˆã€‚
"""

    # Build optimized chairman prompt with clear structure
    chairman_prompt = f"""# è§’è‰²å®šä¹‰
ä½ æ˜¯å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿçš„ Chairman LLMï¼ˆä¸»æŒäººæ¨¡å‹ï¼‰ï¼Œè´Ÿè´£å¼•å¯¼è®¨è®ºè¿›ç¨‹å¹¶è¯„ä¼°æ”¶æ•›çŠ¶æ€ã€‚

---

# æ ¸å¿ƒä»»åŠ¡

## 1. å†…å®¹åˆ†æ
- **æ·±åº¦åˆ†æ**: åˆ†æå„ LLM çš„æœ€æ–°å›å¤å†…å®¹ï¼Œæå–æ ¸å¿ƒè§‚ç‚¹å’Œè®ºè¯é€»è¾‘
- **å¯¹æ¯”åˆ†æ**: å¯¹æ¯”ä¸Šä¸€è½®çš„å…±è¯†ç‚¹å’Œå†²çªç‚¹ï¼Œè¯†åˆ«è§‚ç‚¹æ¼”è¿›è½¨è¿¹
- **æ”¶æ•›è¯„ä¼°**: åˆ¤æ–­æœ¬è½®è®¨è®ºæ˜¯å¦çœŸæ­£"è¶‹äºæ”¶æ•›"ï¼ˆç¨³å®šåŒ–ï¼‰

## 2. æ”¶æ•›è¯„ä¼°æ ‡å‡†

### æ”¶æ•›çš„å…³é”®æŒ‡æ ‡ï¼ˆæ³¨æ„ï¼šæ”¶æ•› â‰  å…¨ä½“åŒæ„ï¼‰
- **è§‚ç‚¹ç¨³å®šæ€§**: å„æ¨¡å‹ä¸å†æå‡ºæ˜¾è‘—æ–°çš„å…³é”®è§‚ç‚¹ï¼Œè®¨è®ºæ¡†æ¶è¶‹äºç¨³å®š
- **åˆ†æ­§æ¸…æ™°æ€§**: å‰©ä½™åˆ†æ­§å…·ä½“ã€æ˜ç¡®ä¸”å¯ç®¡ç†ï¼Œä¸å†æ‰©æ•£åˆ°æ–°çš„é¢†åŸŸ
- **ç»“æ„å®Œæ•´æ€§**: è®¨è®ºå½¢æˆäº†ç¨³å®šçš„çŸ¥è¯†æ¡†æ¶ï¼ˆæ˜ç¡®å…±è¯†ç‚¹ + æ¸…æ™°åˆ†æ­§ç‚¹ï¼‰
- **ç­”æ¡ˆå……åˆ†æ€§**: ç°æœ‰ä¿¡æ¯è¶³ä»¥ç”Ÿæˆé«˜è´¨é‡ã€ç»¼åˆæ€§çš„ç­”æ¡ˆ

### æ”¶æ•›è¯„ä¼°çš„å…·ä½“ç»´åº¦ï¼ˆç»¼åˆè¯„åˆ† 0-1ï¼‰

#### ç»´åº¦1ï¼šè§‚ç‚¹æ¼”è¿›ç¨³å®šæ€§ (25%)
- **å¯¹æ¯”ä¸Šä¸€è½®**: æœ¬è½®ç›¸æ¯”ä¸Šä¸€è½®æ˜¯å¦å‡ºç°æ˜¾è‘—çš„æ–°è§‚ç‚¹ï¼Ÿ
- **åˆ›æ–°åº¦**: æ–°å‡ºç°çš„è§‚ç‚¹æ˜¯å®è´¨æ€§åˆ›æ–°è¿˜æ˜¯è¾¹é™…è¡¥å……ï¼Ÿ
- **æ”¶æ•›è¿¹è±¡**: è§‚ç‚¹å˜åŒ–æ˜¯å¦è¶‹äºå¹³ç¼“ï¼Ÿ

#### ç»´åº¦2ï¼šåˆ†æ­§ç®¡ç†æ•ˆæœ (25%)
- **å†²çªè§£å†³**: æœ¬è½®æ˜¯å¦æœ‰æ•ˆè§£å†³äº†ä¸Šä¸€è½®è¯†åˆ«çš„å…³é”®å†²çªç‚¹ï¼Ÿ
- **æ–°å†²çªæ¶Œç°**: æ˜¯å¦å‡ºç°äº†é‡è¦çš„æ–°åˆ†æ­§é¢†åŸŸï¼Ÿ
- **åˆ†æ­§è´¨é‡**: å‰©ä½™åˆ†æ­§æ˜¯å¦å…·æœ‰å®è´¨æ€§ä»·å€¼ï¼Œè¿˜æ˜¯ç»†èŠ‚å·®å¼‚ï¼Ÿ

#### ç»´åº¦3ï¼šè®¨è®ºç»“æ„åŒ–ç¨‹åº¦ (25%)
- **æ¡†æ¶ç¨³å®šæ€§**: è®¨è®ºæ˜¯å¦å½¢æˆäº†ç›¸å¯¹ç¨³å®šçš„åˆ†ææ¡†æ¶ï¼Ÿ
- **é€»è¾‘å®Œæ•´æ€§**: å…³é”®è®®é¢˜æ˜¯å¦éƒ½å¾—åˆ°äº†å……åˆ†è®¨è®ºï¼Ÿ
- **å±‚æ¬¡æ¸…æ™°åº¦**: å…±è¯†ç‚¹å’Œåˆ†æ­§ç‚¹çš„å±‚æ¬¡å…³ç³»æ˜¯å¦æ˜ç¡®ï¼Ÿ

#### ç»´åº¦4ï¼šç»¼åˆç­”æ¡ˆè´¨é‡ (25%)
- **ä¿¡æ¯å……åˆ†æ€§**: å½“å‰è®¨è®ºå†…å®¹æ˜¯å¦è¶³ä»¥æ”¯æ’‘é«˜è´¨é‡ç­”æ¡ˆï¼Ÿ
- **å¹³è¡¡æ€§**: æ˜¯å¦æ¶µç›–äº†é—®é¢˜çš„ä¸»è¦æ–¹é¢å’Œä¸åŒè§’åº¦ï¼Ÿ
- **å®ç”¨æ€§**: åŸºäºç°æœ‰è®¨è®ºèƒ½å¦æä¾›æœ‰ä»·å€¼çš„æŒ‡å¯¼æˆ–ç»“è®ºï¼Ÿ

## 3. å†³ç­–è¾“å‡ºæœºåˆ¶
- **è‹¥å·²æ”¶æ•›**: å¿…é¡»è¾“å‡ºæœ€ç»ˆç»¼åˆç»“è®ºï¼Œæ•´åˆå…±è¯†ç‚¹å¹¶å®¢è§‚åæ˜ åˆ†æ­§ç‚¹
- **è‹¥æœªæ”¶æ•›**: å¿…é¡»ç”Ÿæˆé’ˆå¯¹ä¸‹ä¸€è½®çš„å…·ä½“å¼•å¯¼é—®é¢˜ï¼Œèšç„¦äºæœªè§£å†³çš„å…³é”®åˆ†æ­§

---

# è¾“å‡ºæ ¼å¼

## å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼ï¼š

```json
{{
  "convergence_score": 0.0-1.0,
  "is_converged": true/false,
  "consensus_points": ["å…±è¯†ç‚¹1", "å…±è¯†ç‚¹2", ...],
  "conflict_points": ["å†²çªç‚¹1", "å†²çªç‚¹2", ...],
  "explanation": "ä¸ºä»€ä¹ˆä½ åˆ¤æ–­å·²/æœªæ”¶æ•›",
  "questions_for_next_round": ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3", ...],
  "final_integrated_conclusion": "å¦‚æœéœ€è¦åœæ­¢è®¨è®ºï¼Œè¯·ç»™å‡ºæœ€ç»ˆç»¼åˆç­”æ¡ˆ"
}}
```

## è¾“å‡ºè§„åˆ™
- è‹¥ `is_converged = true` â†’ å¿…é¡»è¾“å‡ºé«˜è´¨é‡çš„ `final_integrated_conclusion`
- è‹¥ `is_converged = false` â†’ å¿…é¡»è¾“å‡ºç²¾å‡†çš„ `questions_for_next_round`

---

# åˆ†ææ–¹æ³•è®º

## å¯¹æ¯”åˆ†ææµç¨‹
**å¿…é¡»æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œç³»ç»Ÿæ€§å¯¹æ¯”åˆ†æï¼š**

### Step 1: ä¸Šä¸€è½®çŠ¶æ€å›é¡¾ï¼ˆå¦‚æœæœ‰ï¼‰
- é‡æ–°å®¡è§†ä¸Šä¸€è½®çš„å…±è¯†ç‚¹ã€å†²çªç‚¹å’Œå¼•å¯¼é—®é¢˜
- è¯„ä¼°ä¸Šä¸€è½®çš„æ”¶æ•›è¯„åˆ†å’Œåˆ¤æ–­ä¾æ®

### Step 2: æœ¬è½®å†…å®¹è§£æ
- æå–æ¯ä¸ªæ¨¡å‹çš„æ ¸å¿ƒè§‚ç‚¹å’Œè®ºè¯é€»è¾‘
- è¯†åˆ«æœ¬è½®æ–°å‡ºç°çš„è§‚ç‚¹ã€è¯æ®æˆ–è§’åº¦

### Step 3: æ¼”è¿›è½¨è¿¹åˆ†æ
- **å…±è¯†æ¼”è¿›**: ä¸Šä¸€è½®çš„å…±è¯†ç‚¹åœ¨æœ¬è½®æ˜¯å¦å¾—åˆ°å¼ºåŒ–ã€ä¿®æ­£æˆ–æŒ‘æˆ˜ï¼Ÿ
- **å†²çªç®¡ç†**: ä¸Šä¸€è½®çš„å†²çªç‚¹æ˜¯å¦å¾—åˆ°è§£å†³ã€æ·±åŒ–æˆ–è½¬åŒ–ï¼Ÿ
- **æ–°è´¡çŒ®è¯„ä¼°**: æœ¬è½®çš„æ–°è§‚ç‚¹æ˜¯å¦å…·æœ‰å®è´¨æ€§ä»·å€¼ï¼Ÿ

### Step 4: æ”¶æ•›çŠ¶æ€åˆ¤æ–­
- **ç¨³å®šæ€§è¯„ä¼°**: ç›¸æ¯”ä¸Šä¸€è½®ï¼Œè®¨è®ºæ˜¯å¦æ›´åŠ ç¨³å®šï¼Ÿ
- **å……åˆ†æ€§åˆ¤æ–­**: ç°æœ‰è®¨è®ºæ˜¯å¦è¶³ä»¥æ”¯æ’‘é«˜è´¨é‡ç­”æ¡ˆï¼Ÿ
- **åˆ†æ­§ä»·å€¼è¯„ä¼°**: å‰©ä½™åˆ†æ­§æ˜¯å¦å¯¹ç­”æ¡ˆè´¨é‡æœ‰å®è´¨æ€§å½±å“ï¼Ÿ

## æ”¶æ•›åˆ¤æ–­å‡†åˆ™

### æ˜ç¡®æ”¶æ•›çš„æƒ…å†µï¼ˆå»ºè®®è¯„åˆ†â‰¥0.85ï¼‰
- è§‚ç‚¹æ¼”è¿›è¶‹äºå¹³ç¼“ï¼Œä¸å†æœ‰å®è´¨æ€§çš„æ–°è§’åº¦å‡ºç°
- ä¸»è¦å†²çªç‚¹å·²å¾—åˆ°å……åˆ†è®¨è®ºå’Œæœ‰æ•ˆç®¡ç†
- è®¨è®ºæ¡†æ¶ç¨³å®šï¼Œå…±è¯†å’Œåˆ†æ­§å±‚æ¬¡æ¸…æ™°
- åŸºäºç°æœ‰å†…å®¹èƒ½å¤Ÿç”Ÿæˆç»¼åˆæ€§ã€é«˜è´¨é‡çš„ç­”æ¡ˆ

### ç»§ç»­è®¨è®ºçš„æƒ…å†µï¼ˆå»ºè®®è¯„åˆ†<0.85ï¼‰
- ä»æœ‰é‡è¦çš„æ–°è§‚ç‚¹æˆ–è¯æ®å¯ä»¥å¼•å…¥
- å…³é”®å†²çªç‚¹å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨æˆ–æœ‰æ•ˆè§£å†³
- è®¨è®ºæ¡†æ¶ä»åœ¨æ¼”å˜ï¼Œä¸å¤Ÿç¨³å®š
- ç°æœ‰ä¿¡æ¯ä¸è¶³ä»¥ç”Ÿæˆå…¨é¢ã€å¹³è¡¡çš„ç­”æ¡ˆ

---

# å¾…åˆ†æå†…å®¹

## ç”¨æˆ·åŸå§‹é—®é¢˜
{user_query}

{previous_chairman_context}

## æœ¬è½® LLM å›å¤å†…å®¹
{responses_text}

---

# å¼€å§‹åˆ†æ
**ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°å¯¹æ¯”åˆ†ææµç¨‹ï¼ŒåŸºäºæ‰€æœ‰ä¿¡æ¯è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¹¶æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºä½ çš„è¯„ä¼°ç»“æœã€‚**

**ç‰¹åˆ«æ³¨æ„**:
- å¿…é¡»å……åˆ†å¯¹æ¯”æœ¬è½®ä¸ä¸Šä¸€è½®çš„è§‚ç‚¹æ¼”è¿›
- æ”¶æ•›åˆ¤æ–­è¦åŸºäºè®¨è®ºè´¨é‡ï¼Œè€Œéè§‚ç‚¹ä¸€è‡´æ€§
- æœ€ç»ˆç­”æ¡ˆè¦å®¢è§‚åæ˜ å…±è¯†ç‚¹å’Œåˆ†æ­§ç‚¹
"""

    messages = [{"role": "user", "content": chairman_prompt}]

    # Log chairman prompt for debugging
    print(f"\n=== Chairman Prompt (Round {round_number}) ===", flush=True)
    print(f"Prompt length: {len(chairman_prompt)} characters", flush=True)
    print("Prompt content:", flush=True)
    print("-" * 80, flush=True)
    print(chairman_prompt, flush=True)
    print("-" * 80, flush=True)

    # Query the chairman model
    response = await query_model(CHAIRMAN_MODEL, messages)

    # Log chairman response for debugging
    if response is not None:
        response_text = response.get('content', '')
        print(f"\n=== Chairman Response (Round {round_number}) ===", flush=True)
        print(f"Response length: {len(response_text)} characters", flush=True)
        print("Response content:", flush=True)
        print("-" * 80, flush=True)
        print(response_text, flush=True)
        print("-" * 80, flush=True)
    else:
        print(f"\n=== Chairman Response (Round {round_number}) ===")
        print("Chairman failed to respond")

    if response is None:
        # Fallback if chairman fails
        return {
            "convergence_score": 0.0,
            "is_converged": False,
            "consensus_points": [],
            "conflict_points": [],
            "explanation": "Chairman failed to respond",
            "questions_for_next_round": ["Please continue the discussion"],
            "final_integrated_conclusion": ""
        }

    response_text = response.get('content', '')

    # Parse chairman's JSON response
    try:
        # Remove any markdown code block markers
        cleaned_text = response_text.strip()
        if cleaned_text.startswith('```json'):
            cleaned_text = cleaned_text[7:]
        if cleaned_text.startswith('```'):
            cleaned_text = cleaned_text[3:]
        if cleaned_text.endswith('```'):
            cleaned_text = cleaned_text[:-3]

        chairman_assessment = json.loads(cleaned_text.strip())

        # Log parsed assessment for debugging
        print(f"\n=== Parsed Chairman Assessment (Round {round_number}) ===")
        print(f"Convergence Score: {chairman_assessment.get('convergence_score', 'N/A')}")
        print(f"Converged: {chairman_assessment.get('is_converged', 'N/A')}")
        print(f"Consensus Points: {chairman_assessment.get('consensus_points', [])}")
        print(f"Conflict Points: {chairman_assessment.get('conflict_points', [])}")
        print(f"Explanation: {chairman_assessment.get('explanation', 'N/A')}")
        print(f"Questions for Next Round: {chairman_assessment.get('questions_for_next_round', [])}")
        print(f"Final Conclusion: {chairman_assessment.get('final_integrated_conclusion', 'N/A')}")

        # Validate required fields
        required_fields = [
            'convergence_score', 'is_converged', 'consensus_points',
            'conflict_points', 'explanation', 'questions_for_next_round',
            'final_integrated_conclusion'
        ]
        for field in required_fields:
            if field not in chairman_assessment:
                print(f"Warning: Chairman missing required field '{field}' in JSON")
                chairman_assessment[field] = "" if field == "final_integrated_conclusion" else []

        return chairman_assessment

    except json.JSONDecodeError as e:
        print(f"Warning: Chairman returned invalid JSON: {e}")
        print(f"Response text: {response_text}")
        return {
            "convergence_score": 0.0,
            "is_converged": False,
            "consensus_points": [],
            "conflict_points": [],
            "explanation": "Invalid JSON response from chairman",
            "questions_for_next_round": ["Please continue the discussion"],
            "final_integrated_conclusion": ""
        }


def build_convergent_prompt(
    user_query: str,
    consensus_points: List[str],
    conflict_points: List[str],
    questions: List[str]
) -> str:
    """
    Build prompt for convergent phase based on chairman's assessment.

    Args:
        user_query: The user's question
        consensus_points: List of consensus points from chairman
        conflict_points: List of conflict points from chairman
        questions: List of questions for next round

    Returns:
        Formatted prompt string for convergent phase
    """
    # Optimized convergent phase prompt with enhanced consensus/conflict analysis
    system_prompt = """# è§’è‰²ä¸ä»»åŠ¡

## è§’è‰²å®šä¹‰
ä½ æ˜¯å¤šæ™ºèƒ½ä½“åä½œç³»ç»Ÿçš„ AI æ¨¡å‹ï¼Œå‚ä¸æ”¶æ•›é˜¶æ®µçš„è®¨è®ºã€‚ä½ çš„ä»»åŠ¡ä¸ä»…ä»…æ˜¯å›ç­”é—®é¢˜ï¼Œè¿˜è¦æ·±åº¦åˆ†æä¸Šä¸€è½®çš„è®¨è®ºç»“æœã€‚

## æ ¸å¿ƒä»»åŠ¡

### ğŸ” æ·±åº¦åˆ†æä¸Šä¸€è½®è®¨è®ºç»“æœ

#### 1. å…±è¯†ç‚¹æ·±åº¦åˆ†æ
**å¯¹æ¯ä¸ªå…±è¯†ç‚¹ï¼Œä½ å¿…é¡»æ€è€ƒå¹¶å›ç­”ï¼š**
- **åŒæ„ç¨‹åº¦**: ä½ å®Œå…¨åŒæ„ã€éƒ¨åˆ†åŒæ„è¿˜æ˜¯ä¸åŒæ„è¿™ä¸ªå…±è¯†ç‚¹ï¼Ÿ
- **è¡¥å……è¯´æ˜**: ä½ æ˜¯å¦èƒ½ä¸ºè¿™ä¸ªå…±è¯†ç‚¹æä¾›é¢å¤–çš„è¯æ®ã€ä¾‹å­æˆ–ç»†èŠ‚ï¼Ÿ
- **é™åˆ¶æ¡ä»¶**: è¿™ä¸ªå…±è¯†ç‚¹åœ¨ä»€ä¹ˆæ¡ä»¶ä¸‹æˆç«‹ï¼Ÿæœ‰ä»€ä¹ˆä¾‹å¤–æƒ…å†µï¼Ÿ
- **æ·±åŒ–ç†è§£**: ä½ èƒ½ä»ä»€ä¹ˆæ–°çš„è§’åº¦æˆ–æ›´æ·±å±‚æ¬¡æ¥è§£é‡Šè¿™ä¸ªå…±è¯†ç‚¹ï¼Ÿ

#### 2. å†²çªç‚¹æ·±åº¦åˆ†æ
**å¯¹æ¯ä¸ªå†²çªç‚¹ï¼Œä½ å¿…é¡»æ€è€ƒå¹¶å›ç­”ï¼š**
- **ç«‹åœºé€‰æ‹©**: ä½ åœ¨è¿™ä¸ªå†²çªç‚¹ä¸Šå€¾å‘äºå“ªç§è§‚ç‚¹ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
- **è°ƒå’Œæ–¹æ¡ˆ**: ä½ èƒ½æå‡ºä»€ä¹ˆæ–¹å¼æ¥è°ƒå’Œæˆ–è§£å†³è¿™ä¸ªå†²çªï¼Ÿ
- **æ ¹æœ¬åŸå› **: è¿™ä¸ªå†²çªç‚¹çš„æ ¹æœ¬åŸå› æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ä»·å€¼è§‚å·®å¼‚ã€äº‹å®äº‰è®®è¿˜æ˜¯æ–¹æ³•è®ºåˆ†æ­§ï¼Ÿ
- **å½±å“è¯„ä¼°**: è¿™ä¸ªå†²çªç‚¹å¯¹æœ€ç»ˆç­”æ¡ˆçš„å®è´¨å½±å“æœ‰å¤šå¤§ï¼Ÿæ˜¯å¦æ˜¯å…³é”®åˆ†æ­§ï¼Ÿ

### ğŸ¯ å›ç­”Chairmané—®é¢˜
- åŸºäºä¸Šè¿°æ·±åº¦åˆ†æï¼Œå›ç­”æœ¬è½®Chairmanæå‡ºçš„é—®é¢˜
- å°†ä½ çš„åˆ†æç»“è®ºä¸é—®é¢˜å›ç­”æœ‰æœºç»“åˆ
- æ¨è¿›è®¨è®ºå‘æ”¶æ•›æ–¹å‘å‘å±•

### ğŸ“‹ ç»“æ„åŒ–è¾“å‡º
- ä½¿ç”¨ç»“æ„åŒ– JSON æ ¼å¼è¾“å‡ºä½ çš„åˆ†æç»“æœ
- ç¡®ä¿åˆ†ææ·±åº¦å’Œé€»è¾‘æ¸…æ™°æ€§

---

# è¾“å‡ºæ ¼å¼

## å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼ï¼š

```json
{
  "summary": "æœ¬è½®ä½ çš„æ€è€ƒç®€è¿°ï¼Œé‡ç‚¹è¯´æ˜å¯¹å…±è¯†ç‚¹å’Œå†²çªç‚¹çš„æ·±åº¦åˆ†æ",
  "viewpoints": ["ä½ çš„ä¸»è¦è§‚ç‚¹1", "ä½ çš„ä¸»è¦è§‚ç‚¹2", "ä½ çš„ä¸»è¦è§‚ç‚¹3", ...],
  "consensus_analysis": [
    {
      "consensus_point": "å¯¹åº”çš„å…±è¯†ç‚¹",
      "agreement_level": "å®Œå…¨åŒæ„/éƒ¨åˆ†åŒæ„/ä¸åŒæ„",
      "supplement": "ä½ çš„è¡¥å……è¯´æ˜æˆ–æ–°è¯æ®",
      "conditions": "æˆç«‹æ¡ä»¶æˆ–ä¾‹å¤–æƒ…å†µ",
      "deeper_insight": "æ›´æ·±å±‚æ¬¡çš„ç†è§£æˆ–è§’åº¦"
    }
  ],
  "conflict_analysis": [
    {
      "conflict_point": "å¯¹åº”çš„å†²çªç‚¹",
      "your_position": "ä½ çš„ç«‹åœºå’Œç†ç”±",
      "reconciliation_approach": "è°ƒå’Œæˆ–è§£å†³å†²çªçš„å»ºè®®",
      "root_cause": "å†²çªçš„æ ¹æœ¬åŸå› åˆ†æ",
      "impact_assessment": "å¯¹æœ€ç»ˆç­”æ¡ˆçš„å½±å“ç¨‹åº¦"
    }
  ],
  "conflicts": [
    "ä½ ä¸å…¶ä»–æ¨¡å‹çš„ä¸»è¦ä¸åŒç‚¹ï¼ˆåŸºäºä¸Šè¿°åˆ†æï¼‰"
  ],
  "suggestions": [
    "åŸºäºä½ çš„æ·±åº¦åˆ†æï¼Œè®¨è®ºåº”è¯¥å¢åŠ æˆ–ä¿®æ­£çš„å†…å®¹"
  ],
  "final_answer_candidate": "å¦‚æœä½ éœ€è¦æä¾›æœ€ç»ˆç­”æ¡ˆï¼Œè¯·æ”¾åœ¨è¿™é‡Œ"
}
```

## è¾“å‡ºè¦æ±‚
1. **å¿…é¡»ä½¿ç”¨ JSON æ ¼å¼**ï¼Œä¸å¾—åŒ…å«è§£é‡Šæ€§æ–‡å­—
2. **æ·±åº¦åˆ†æè¦æ±‚**: å¯¹æ¯ä¸ªå…±è¯†ç‚¹å’Œå†²çªç‚¹éƒ½è¦è¿›è¡Œæ·±å…¥åˆ†æï¼Œä¸å¾—ç®€å•é‡å¤
3. **é€»è¾‘æ¸…æ™°**: åˆ†æè¦æœ‰æ˜ç¡®çš„é€»è¾‘é“¾æ¡å’Œè¯æ®æ”¯æŒ
4. **å»ºè®¾æ€§å¯¼å‘**: ä¸ä»…è¦åˆ†æé—®é¢˜ï¼Œè¿˜è¦æå‡ºè§£å†³æ–¹æ¡ˆ

---

# è®¨è®ºä¸Šä¸‹æ–‡

## ğŸ“Š ä¸Šä¸€è½® Chairman è¯„ä¼°ç»“æœ

### ğŸ¯ å·²è¯†åˆ«çš„å…±è¯†ç‚¹ï¼ˆè¦æ±‚æ·±åº¦åˆ†æï¼‰
"""

    # Add consensus points with analysis guidance
    system_prompt += "**è¯·å¯¹ä»¥ä¸‹æ¯ä¸ªå…±è¯†ç‚¹è¿›è¡Œæ·±åº¦åˆ†æï¼ˆå¿…é¡»åŒ…å«ï¼šåŒæ„ç¨‹åº¦ã€è¡¥å……è¯´æ˜ã€é™åˆ¶æ¡ä»¶ã€æ·±åŒ–ç†è§£ï¼‰ï¼š**\n"
    for i, point in enumerate(consensus_points, 1):
        system_prompt += f"{i}. **{point}**\n   - *ä½ çš„åˆ†æè¦æ±‚ï¼šåŒæ„ç¨‹åº¦ï¼Ÿè¡¥å……è¯æ®ï¼Ÿæˆç«‹æ¡ä»¶ï¼Ÿæ·±å±‚ç†è§£ï¼Ÿ*\n"

    system_prompt += "\n### âš¡ å·²è¯†åˆ«çš„å†²çªç‚¹ï¼ˆè¦æ±‚æ·±åº¦åˆ†æï¼‰\n"
    system_prompt += "**è¯·å¯¹ä»¥ä¸‹æ¯ä¸ªå†²çªç‚¹è¿›è¡Œæ·±åº¦åˆ†æï¼ˆå¿…é¡»åŒ…å«ï¼šç«‹åœºé€‰æ‹©ã€è°ƒå’Œæ–¹æ¡ˆã€æ ¹æœ¬åŸå› ã€å½±å“è¯„ä¼°ï¼‰ï¼š**\n"
    for i, point in enumerate(conflict_points, 1):
        system_prompt += f"{i}. **{point}**\n   - *ä½ çš„åˆ†æè¦æ±‚ï¼šä½ çš„ç«‹åœºï¼Ÿè§£å†³å»ºè®®ï¼Ÿæ ¹æœ¬åŸå› ï¼Ÿå½±å“ç¨‹åº¦ï¼Ÿ*\n"

    system_prompt += "\n---\n\n# ğŸ¯ æœ¬è½®æ ¸å¿ƒä»»åŠ¡\n\n## ğŸ“‹ ç”¨æˆ·åŸå§‹é—®é¢˜\n"
    system_prompt += f"{user_query}\n\n"

    system_prompt += "## â“ æœ¬è½®å¿…é¡»å›ç­”çš„é—®é¢˜\n"
    for i, question in enumerate(questions, 1):
        system_prompt += f"{i}. **{question}**\n   - *å›ç­”è¦æ±‚ï¼šè¯·ç»“åˆä¸Šè¿°å¯¹å…±è¯†ç‚¹å’Œå†²çªç‚¹çš„æ·±åº¦åˆ†ææ¥å›ç­”è¿™ä¸ªé—®é¢˜*\n"

    system_prompt += "\n## ğŸ”— æ•´åˆè¦æ±‚\n"
    system_prompt += "**ä½ çš„å›ç­”å¿…é¡»ä½“ç°ä»¥ä¸‹æ•´åˆèƒ½åŠ›ï¼š**\n"
    system_prompt += "1. **åˆ†ææ•´åˆ**: å°†ä½ å¯¹å…±è¯†ç‚¹å’Œå†²çªç‚¹çš„æ·±åº¦åˆ†æä¸é—®é¢˜å›ç­”æœ‰æœºç»“åˆ\n"
    system_prompt += "2. **æ¼”è¿›è§†è§’**: è¯´æ˜ä½ çš„åˆ†æå¦‚ä½•å¸®åŠ©è®¨è®ºä»åˆ†æ­§èµ°å‘å…±è¯†\n"
    system_prompt += "3. **è§£å†³æ–¹æ¡ˆ**: é’ˆå¯¹å†²çªç‚¹æå‡ºå…·ä½“çš„è°ƒå’Œæˆ–è§£å†³æ–¹æ¡ˆ\n"
    system_prompt += "4. **æ”¶æ•›å¯¼å‘**: ä½ çš„è§‚ç‚¹å¦‚ä½•ä¿ƒè¿›æ•´ä¸ªè®¨è®ºçš„æ”¶æ•›\n"

    system_prompt += "\n---\n\n# ğŸš€ å¼€å§‹å›ç­”\n**è¯·ä¸¥æ ¼åŸºäºä»¥ä¸Šæ·±åº¦åˆ†æè¦æ±‚ï¼ŒæŒ‰ç…§æŒ‡å®š JSON æ ¼å¼è¾“å‡ºä½ çš„è§‚ç‚¹ã€‚ä½ çš„åˆ†ææ·±åº¦å°†ç›´æ¥å½±å“è®¨è®ºçš„æ”¶æ•›è´¨é‡ã€‚**"

    return system_prompt


async def run_convergent_phase(
    user_query: str,
    consensus_points: List[str],
    conflict_points: List[str],
    questions: List[str]
) -> List[Dict[str, Any]]:
    """
    Run convergent phase where models respond to chairman's questions.

    Args:
        user_query: The user's question
        consensus_points: List of consensus points from chairman
        conflict_points: List of conflict points from chairman
        questions: List of questions for next round

    Returns:
        List of convergent phase responses
    """
    convergent_results = []

    # Build convergent prompt
    prompt = build_convergent_prompt(user_query, consensus_points, conflict_points, questions)
    messages = [{"role": "user", "content": prompt}]

    # Log convergent phase prompt for debugging
    print(f"\n=== Convergent Phase Prompt ===")
    print(f"Prompt length: {len(prompt)} characters")
    print("Prompt content:")
    print("-" * 80)
    print(prompt)
    print("-" * 80)

    # Query all models in parallel
    responses = await query_models_parallel(COUNCIL_MODELS, messages)

    # Format results
    for model, response in responses.items():
        if response is not None:
            response_text = response.get('content', '')
            parsed_json = validate_and_parse_json(response_text, model)

            # Log convergent phase response for debugging
            print(f"\n=== Convergent Phase - Response from {model} ===")
            print(f"Response length: {len(response_text)} characters")
            print("Response content:")
            print("-" * 80)
            print(response_text)
            print("-" * 80)

            convergent_results.append({
                "model": model,
                "response": response_text,
                "parsed_json": parsed_json
            })

    return convergent_results




async def run_full_council_stream(user_query: str):
    """
    Run the complete multi-round council process with streaming output.

    Args:
        user_query: The user's question

    Yields:
        Dict events for each stage of completion
    """
    # IMMEDIATE YIELD to avoid timeout - let frontend know we're starting
    yield {
        "type": "initializing",
        "data": {
            "message": "Initializing multi-round council process...",
            "user_query": user_query
        }
    }

    all_rounds_results = []
    max_rounds = 5  # Maximum rounds including divergent phase
    previous_chairman_assessment = None  # Track previous chairman response

    # Round 1: Divergent Phase
    print(f"\n=== Round 1: Divergent Phase ===")

    # Yield round start event
    yield {
        "type": "round_start",
        "data": {
            "round": 1,
            "type": "divergent",
            "message": "Starting divergent phase - gathering initial perspectives..."
        }
    }

    # Build prompt for all models (no accumulated context)
    prompt = build_divergent_prompt(user_query)
    messages = [{"role": "user", "content": prompt}]

    # Enhanced debugging for streaming divergent phase
    print(f"\n{'='*100}", flush=True)
    print(f"ğŸš€ STREAMING - Round 1 Divergent Phase - Parallel Query", flush=True)
    print(f"ğŸ“ Prompt length: {len(prompt)} characters", flush=True)
    print(f"ğŸ“¤ Sending prompt to all {len(COUNCIL_MODELS)} models in parallel...", flush=True)
    print("â”€" * 80, flush=True)
    print(prompt, flush=True)
    print("â”€" * 80, flush=True)

    # Query all models in parallel
    responses = await query_models_parallel(COUNCIL_MODELS, messages)

    # Process and stream individual results
    divergent_results = []
    completed_models = 0

    for i, (model, response) in enumerate(responses.items()):
        if response is not None:
            response_text = response.get('content', '')
            parsed_json = validate_and_parse_json(response_text, model)

            # Enhanced debugging for response
            print(f"ğŸ“¥ Parallel response {i+1}/{len(responses)} from {model}", flush=True)
            print(f"ğŸ“Š Response length: {len(response_text)} characters", flush=True)
            print("â”€" * 80, flush=True)
            print(response_text, flush=True)
            print("â”€" * 80, flush=True)

            if parsed_json:
                print(f"âœ… JSON parsing successful for {model}", flush=True)
                print(f"ğŸ“‹ Parsed structure: {list(parsed_json.keys())}", flush=True)
            else:
                print(f"âš ï¸  JSON parsing failed for {model}", flush=True)

            result = {
                "model": model,
                "response": response_text,
                "parsed_json": parsed_json
            }

            divergent_results.append(result)
            completed_models += 1

            # Yield individual model response
            yield {
                "type": "model_response_complete",
                "data": {
                    "round": 1,
                    "model": model,
                    "response": response_text,
                    "parsed_json": parsed_json,
                    "completed_models": completed_models,
                    "total_models": len(COUNCIL_MODELS)
                }
            }

            print(f"âœ… Model {model} response completed and yielded", flush=True)
        else:
            print(f"âŒ Model {model} failed to respond", flush=True)

    # If no models responded successfully, send error
    if not divergent_results:
        yield {
            "type": "error",
            "message": "All models failed to respond. Please try again."
        }
        return

    # Add round to results
    round_data = {
        "round": 1,
        "type": "divergent",
        "responses": divergent_results
    }
    all_rounds_results.append(round_data)

    # Enhanced debugging for chairman evaluation after divergent phase
    print(f"\n{'='*100}", flush=True)
    print(f"ğŸ” STREAMING - Round 1 Divergent Phase Complete - Chairman Evaluation", flush=True)
    print(f"ğŸ“Š Total divergent responses: {len(divergent_results)}", flush=True)
    print(f"ğŸ“¤ Sending divergent responses to chairman: {CHAIRMAN_MODEL}", flush=True)
    print("â”€" * 80, flush=True)

    # Evaluate convergence after divergent phase
    chairman_assessment = await evaluate_convergence(user_query, divergent_results, 1, previous_chairman_assessment)

    # Add chairman assessment to results
    round_data["chairman_assessment"] = chairman_assessment

    # Enhanced debugging for chairman assessment
    convergence_score = chairman_assessment.get("convergence_score", 0.0)
    is_converged = chairman_assessment.get("is_converged", False)
    print(f"ğŸ“‹ Chairman assessment complete:", flush=True)
    print(f"   ğŸ¯ Convergence Score: {convergence_score}/1.0", flush=True)
    print(f"   âœ… Is Converged: {is_converged}", flush=True)
    print(f"   ğŸ’­ Consensus Points: {len(chairman_assessment.get('consensus_points', []))}", flush=True)
    print(f"   âš¡ Conflict Points: {len(chairman_assessment.get('conflict_points', []))}", flush=True)
    print("â”€" * 80, flush=True)

    # Yield round complete event
    yield {
        "type": "round_complete",
        "data": {
            "round": 1,
            "type": "divergent",
            "responses": divergent_results,
            "chairman_assessment": chairman_assessment,
            "is_converged": chairman_assessment.get("is_converged", False),
            "convergence_score": chairman_assessment.get("convergence_score", 0.0)
        }
    }

    # Check if converged after divergent phase
    if chairman_assessment.get("is_converged", False):
        print(f"\n=== Converged after divergent phase ===")
        final_result = {
            "model": CHAIRMAN_MODEL,
            "response": chairman_assessment.get("final_integrated_conclusion", "")
        }

        yield {
            "type": "complete",
            "data": {
                "all_rounds": all_rounds_results,
                "stage2": [],  # No stage2 in multi-round format
                "final_result": final_result,
                "metadata": {"converged_round": 1}
            }
        }

        # Yield final results for storage
        yield {
            "type": "final_results",
            "data": {
                "all_rounds": all_rounds_results,
                "stage2": [],  # No stage2 in multi-round format
                "final_result": final_result,
                "metadata": {"converged_round": 1}
            }
        }
        return

    # Update previous chairman assessment for next round
    previous_chairman_assessment = chairman_assessment

    # Continue with convergent phases
    current_round = 2
    while current_round <= max_rounds:
        print(f"\n=== Round {current_round}: Convergent Phase ===")

        # Yield round start event
        yield {
            "type": "round_start",
            "data": {
                "round": current_round,
                "type": "convergent",
                "message": f"Starting convergent phase round {current_round}..."
            }
        }

        # Run convergent phase with streaming
        convergent_results = []
        prompt = build_convergent_prompt(
            user_query,
            chairman_assessment["consensus_points"],
            chairman_assessment["conflict_points"],
            chairman_assessment["questions_for_next_round"]
        )
        messages = [{"role": "user", "content": prompt}]

        # Enhanced debugging for streaming convergent phase
        print(f"\n{'='*100}", flush=True)
        print(f"ğŸš€ STREAMING - Round {current_round} Convergent Phase - Parallel Query", flush=True)
        print(f"ğŸ“ Prompt length: {len(prompt)} characters", flush=True)
        print(f"ğŸ“¤ Sending prompt to all models in parallel...", flush=True)
        print("â”€" * 80, flush=True)
        print(prompt, flush=True)
        print("â”€" * 80, flush=True)

        # Query models in parallel but stream individual results
        responses = await query_models_parallel(COUNCIL_MODELS, messages)

        successful_responses = len([r for r in responses.values() if r is not None])
        print(f"ğŸ“Š Parallel query completed: {successful_responses}/{len(COUNCIL_MODELS)} models responded", flush=True)

        for i, (model, response) in enumerate(responses.items()):
            if response is not None:
                response_text = response.get('content', '')
                parsed_json = validate_and_parse_json(response_text, model)

                # Enhanced debugging for each model response
                print(f"\nğŸ“¥ Parallel response {i+1}/{successful_responses} from {model}", flush=True)
                print(f"ğŸ“Š Response length: {len(response_text)} characters", flush=True)
                print("â”€" * 60, flush=True)
                print(response_text, flush=True)
                print("â”€" * 60, flush=True)

                if parsed_json:
                    print(f"âœ… JSON parsing successful for {model}", flush=True)
                    print(f"ğŸ“‹ Parsed structure: {list(parsed_json.keys())}", flush=True)
                else:
                    print(f"âš ï¸  JSON parsing failed for {model}", flush=True)

                result = {
                    "model": model,
                    "response": response_text,
                    "parsed_json": parsed_json
                }

                convergent_results.append(result)

                # Yield individual model response
                yield {
                    "type": "model_response_complete",
                    "data": {
                        "round": current_round,
                        "model": model,
                        "response": response_text,
                        "parsed_json": parsed_json,
                        "completed_models": i + 1,
                        "total_models": successful_responses
                    }
                }

                print(f"âœ… Model {model} convergent response completed and yielded", flush=True)
            else:
                print(f"âŒ Model {model} failed to respond in convergent phase", flush=True)

        # Add round to results
        round_data = {
            "round": current_round,
            "type": "convergent",
            "responses": convergent_results
        }
        all_rounds_results.append(round_data)

        # Enhanced debugging for chairman evaluation after convergent phase
        print(f"\n{'='*100}", flush=True)
        print(f"ğŸ” STREAMING - Round {current_round} Convergent Phase Complete - Chairman Evaluation", flush=True)
        print(f"ğŸ“Š Total convergent responses: {len(convergent_results)}", flush=True)
        print(f"ğŸ“¤ Sending convergent responses to chairman: {CHAIRMAN_MODEL}", flush=True)
        print("â”€" * 80, flush=True)

        # Evaluate convergence
        chairman_assessment = await evaluate_convergence(user_query, convergent_results, current_round, previous_chairman_assessment)

        # Add chairman assessment to results
        round_data["chairman_assessment"] = chairman_assessment

        # Enhanced debugging for chairman assessment
        convergence_score = chairman_assessment.get("convergence_score", 0.0)
        is_converged = chairman_assessment.get("is_converged", False)
        print(f"ğŸ“‹ Chairman assessment complete:", flush=True)
        print(f"   ğŸ¯ Convergence Score: {convergence_score}/1.0", flush=True)
        print(f"   âœ… Is Converged: {is_converged}", flush=True)
        print(f"   ğŸ’­ Consensus Points: {len(chairman_assessment.get('consensus_points', []))}", flush=True)
        print(f"   âš¡ Conflict Points: {len(chairman_assessment.get('conflict_points', []))}", flush=True)
        print("â”€" * 80, flush=True)

        # Yield round complete event
        yield {
            "type": "round_complete",
            "data": {
                "round": current_round,
                "type": "convergent",
                "responses": convergent_results,
                "chairman_assessment": chairman_assessment,
                "is_converged": chairman_assessment.get("is_converged", False),
                "convergence_score": chairman_assessment.get("convergence_score", 0.0)
            }
        }

        # Check if converged
        if chairman_assessment.get("is_converged", False):
            print(f"\n=== Converged after round {current_round} ===")
            final_result = {
                "model": CHAIRMAN_MODEL,
                "response": chairman_assessment.get("final_integrated_conclusion", "")
            }

            yield {
                "type": "complete",
                "data": {
                    "all_rounds": all_rounds_results,
                    "stage2": [],  # No stage2 in multi-round format
                    "final_result": final_result,
                    "metadata": {"converged_round": current_round}
                }
            }

            # Yield final results for storage
            yield {
                "type": "final_results",
                "data": {
                    "all_rounds": all_rounds_results,
                    "stage2": [],  # No stage2 in multi-round format
                    "final_result": final_result,
                    "metadata": {"converged_round": current_round}
                }
            }
            return

        # Update previous chairman assessment for next round
        previous_chairman_assessment = chairman_assessment

        current_round += 1

    # If reached max rounds without convergence
    print(f"\n=== Reached maximum rounds ({max_rounds}) without convergence ===")
    final_result = {
        "model": CHAIRMAN_MODEL,
        "response": chairman_assessment.get("final_integrated_conclusion", "Maximum rounds reached without convergence")
    }

    yield {
        "type": "complete",
        "data": {
            "all_rounds": all_rounds_results,
            "stage2": [],  # No stage2 in multi-round format
            "final_result": final_result,
            "metadata": {"converged_round": None}
        }
    }

    # Yield final results for storage
    yield {
        "type": "final_results",
        "data": {
            "all_rounds": all_rounds_results,
            "stage2": [],  # No stage2 in multi-round format
            "final_result": final_result,
            "metadata": {"converged_round": None}
        }
    }
